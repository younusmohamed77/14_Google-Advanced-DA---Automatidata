{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtNBZFHO3M7n"
   },
   "source": [
    "# **Automatidata project**\n",
    "**Course 5 - Regression Analysis: Simplify complex data relationships**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaOj1equPMAb"
   },
   "source": [
    "The data consulting firm Automatidata has recently hired you as the newest member of their data analytics team. Their newest client, the NYC Taxi and Limousine Commission (New York City TLC), wants the Automatidata team to build a multiple linear regression model to predict taxi fares using existing data that was collected over the course of a year. The team is getting closer to completing the project, having completed an initial plan of action, initial Python coding work, EDA, and A/B testing.\n",
    "\n",
    "The Automatidata team has reviewed the results of the A/B testing. Now it’s time to work on predicting the taxi fare amounts. You’ve impressed your Automatidata colleagues with your hard work and attention to detail. The data team believes that you are ready to build the regression model and update the client New York City TLC about your progress.\n",
    "\n",
    "A notebook was structured and prepared to help you in this project. Please complete the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgSbVJvomcVa"
   },
   "source": [
    "# Course 5 End-of-course project: Build a multiple linear regression model\n",
    "\n",
    "In this activity, you will build a multiple linear regression model. As you've learned, multiple linear regression helps you estimate the linear relationship between one continuous dependent variable and two or more independent variables. For data science professionals, this is a useful skill because it allows you to consider more than one variable against the variable you're measuring against. This opens the door for much more thorough and flexible analysis to be completed. \n",
    "\n",
    "Completing this activity will help you practice planning out and buidling a multiple linear regression model based on a specific business need. The structure of this activity is designed to emulate the proposals you will likely be assigned in your career as a data professional. Completing this activity will help prepare you for those career moments.\n",
    "<br/>\n",
    "\n",
    "**The purpose** of this project is to demostrate knowledge of EDA and a multiple linear regression model\n",
    "\n",
    "**The goal** is to build a multiple linear regression model and evaluate the model\n",
    "<br/>\n",
    "*This activity has three parts:*\n",
    "\n",
    "**Part 1:** EDA & Checking Model Assumptions\n",
    "* What are some purposes of EDA before constructing a multiple linear regression model?\n",
    "\n",
    "**Part 2:** Model Building and evaluation\n",
    "* What resources do you find yourself using as you complete this stage?\n",
    "\n",
    "**Part 3:** Interpreting Model Results\n",
    "\n",
    "* What key insights emerged from your model(s)?\n",
    "\n",
    "* What business recommendations do you propose based on the models built?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KFOyc3JPSiN"
   },
   "source": [
    "# Build a multiple linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UCHQclzQDUL"
   },
   "source": [
    "<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "# **PACE stages**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout these project notebooks, you'll see references to the problem-solving framework PACE. The following notebook components are labeled with the respective PACE stage: Plan, Analyze, Construct, and Execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5O5cx_qQJmX"
   },
   "source": [
    "<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "\n",
    "## PACE: **Plan**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Plan stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8qYlvkLQsf2"
   },
   "source": [
    "### Task 1. Imports and loading\n",
    "Import the packages that you've learned are needed for building linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ccfeg6X6eOVZ"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2017_Yellow_Taxi_Trip_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load dataset into dataframe\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m taxi_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2017_Yellow_Taxi_Trip_Data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2017_Yellow_Taxi_Trip_Data.csv'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# Packages for numerics + dataframes\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Packages for visualization\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Packages for date conversions for calculating trip durations\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Packages for OLS, MLR, confusion matrix\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load dataset into dataframe\n",
    "taxi_data = pd.read_csv(\"2017_Yellow_Taxi_Trip_Data.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhSYPrzQ2lpH"
   },
   "source": [
    "**Note:** `Pandas` is used to load the NYC TLC dataset. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyR3sBUYJBO8"
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframe \n",
    "df0=pd.read_csv(\"2017_Yellow_Taxi_Trip_Data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnrvCSfHUWPv"
   },
   "source": [
    "<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Analyze**\n",
    "\n",
    "In this stage, consider the following question where applicable to complete your code response:\n",
    "\n",
    "* What are some purposes of EDA before constructing a multiple linear regression model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIcDG2e66wt9"
   },
   "source": [
    "### Task 2a. Explore data with EDA\n",
    "\n",
    "Analyze and discover data, looking for correlations, missing data, outliers, and duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLpoUCz1277k"
   },
   "source": [
    "Start with `.shape` and `.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4Ag-sZhWg6K"
   },
   "outputs": [],
   "source": [
    "# Start with `.shape` and `.info()`\n",
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWLHv_h_3Hcf"
   },
   "source": [
    "Check for missing data and duplicates using `.isna()` and `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QZZIxxi3OV3"
   },
   "outputs": [],
   "source": [
    "# Check for missing data and duplicates using .isna() and .drop_duplicates()\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXWAlPTY9iLK"
   },
   "source": [
    "Use `.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2O3b9H9B9nwk"
   },
   "outputs": [],
   "source": [
    "# Use .describe()\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXhaBfP_WOSR"
   },
   "source": [
    "### Task 2b. Convert pickup & dropoff columns to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbHu-SSInJCX"
   },
   "outputs": [],
   "source": [
    "# Check the format of the data\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5L6OdYPqV0N"
   },
   "outputs": [],
   "source": [
    "# Convert datetime columns to datetime\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlF7ZNSyW0yV"
   },
   "source": [
    "### Task 2c. Create duration column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1v_Y1uunbsx"
   },
   "source": [
    "Create a new column called `duration` that represents the total number of minutes that each taxi ride took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suC4LJFPMPCo"
   },
   "outputs": [],
   "source": [
    "# Create `duration` column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dcytBKhiGAr"
   },
   "source": [
    "### Outliers\n",
    "\n",
    "Call `df.info()` to inspect the columns and decide which ones to check for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5bCdL5SSfg1"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7VR2S0izZE"
   },
   "source": [
    "Keeping in mind that many of the features will not be used to fit your model, the most important columns to check for outliers are likely to be:\n",
    "* `trip_distance`\n",
    "* `fare_amount`\n",
    "* `duration`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtj4iAJMk9Vc"
   },
   "source": [
    "### Task 2d. Box plots\n",
    "\n",
    "Plot a box plot for each feature: `trip_distance`, `fare_amount`, `duration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCEzE-gwL5gq"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqcGiHLa4TvP"
   },
   "source": [
    "**Questions:** \n",
    "1. Which variable(s) contains outliers? \n",
    "\n",
    "2. Are the values in the `trip_distance` column unbelievable?\n",
    "\n",
    "3. What about the lower end? Do distances, fares, and durations of 0 (or negative values) make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FetTHatPoR6n"
   },
   "source": [
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2e. Imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `trip_distance` outliers\n",
    "\n",
    "You know from the summary statistics that there are trip distances of 0. Are these reflective of erroneous data, or are they very short trips that get rounded down?\n",
    "\n",
    "To check, sort the column values, eliminate duplicates, and inspect the least 10 values. Are they rounded values or precise values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are trip distances of 0 bad data or very short trips rounded down?\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distances are captured with a high degree of precision. However, it might be possible for trips to have distances of zero if a passenger summoned a taxi and then changed their mind. Besides, are there enough zero values in the data to pose a problem?\n",
    "\n",
    "Calculate the count of rides where the `trip_distance` is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fare_amount` outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you notice about the values in the `fare_amount` column?\n",
    "\n",
    "Impute values less than $0 with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute values less than $0 with 0\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now impute the maximum value as `Q3 + (6 * IQR)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "    '''\n",
    "    Impute upper-limit values in specified columns based on their interquartile range.\n",
    "\n",
    "    Arguments:\n",
    "        column_list: A list of columns to iterate over\n",
    "        iqr_factor: A number representing x in the formula:\n",
    "                    Q3 + (x * IQR). Used to determine maximum threshold,\n",
    "                    beyond which a point is considered an outlier.\n",
    "\n",
    "    The IQR is computed for each column in column_list and values exceeding\n",
    "    the upper threshold for each column are imputed with the upper threshold value.\n",
    "    '''\n",
    "  ### YOUR CODE HERE ###\n",
    "        # Reassign minimum to zero\n",
    "        ### YOUR CODE HERE ###\n",
    "\n",
    "        # Calculate upper threshold\n",
    "     ### YOUR CODE HERE ###\n",
    "\n",
    "        # Reassign values > threshold to threshold\n",
    "      ### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `duration` outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call .describe() for duration outliers\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `duration` column has problematic values at both the lower and upper extremities.\n",
    "\n",
    "* **Low values:** There should be no values that represent negative time. Impute all negative durations with `0`.\n",
    "\n",
    "* **High values:** Impute high values the same way you imputed the high-end outliers for fares: `Q3 + (6 * IQR)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute a 0 for any negative values\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the high outliers\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `mean_distance` column\n",
    "\n",
    "When deployed, the model will not know the duration of a trip until after the trip occurs, so you cannot train a model that uses this feature. However, you can use the statistics of trips you *do* know to generalize about ones you do not know.\n",
    "\n",
    "In this step, create a column called `mean_distance` that captures the mean distance for each group of trips that share pickup and dropoff points.\n",
    "\n",
    "For example, if your data were:\n",
    "\n",
    "|Trip|Start|End|Distance|\n",
    "|--: |:---:|:-:|    |\n",
    "| 1  | A   | B | 1  |\n",
    "| 2  | C   | D | 2  |\n",
    "| 3  | A   | B |1.5 |\n",
    "| 4  | D   | C | 3  |\n",
    "\n",
    "The results should be:\n",
    "```\n",
    "A -> B: 1.25 miles\n",
    "C -> D: 2 miles\n",
    "D -> C: 3 miles\n",
    "```\n",
    "\n",
    "Notice that C -> D is not the same as D -> C. All trips that share a unique pair of start and end points get grouped and averaged.\n",
    "\n",
    "Then, a new column `mean_distance` will be added where the value at each row is the average for all trips with those pickup and dropoff locations:\n",
    "\n",
    "|Trip|Start|End|Distance|mean_distance|\n",
    "|--: |:---:|:-:|  :--   |:--   |\n",
    "| 1  | A   | B | 1      | 1.25 |\n",
    "| 2  | C   | D | 2      | 2    |\n",
    "| 3  | A   | B |1.5     | 1.25 |\n",
    "| 4  | D   | C | 3      | 3    |\n",
    "\n",
    "\n",
    "Begin by creating a helper column called `pickup_dropoff`, which contains the unique combination of pickup and dropoff location IDs for each row.\n",
    "\n",
    "One way to do this is to convert the pickup and dropoff location IDs to strings and join them, separated by a space. The space is to ensure that, for example, a trip with pickup/dropoff points of 12 & 151 gets encoded differently than a trip with points 121 & 51.\n",
    "\n",
    "So, the new column would look like this:\n",
    "\n",
    "|Trip|Start|End|pickup_dropoff|\n",
    "|--: |:---:|:-:|  :--         |\n",
    "| 1  | A   | B | 'A B'        |\n",
    "| 2  | C   | D | 'C D'        |\n",
    "| 3  | A   | B | 'A B'        |\n",
    "| 4  | D   | C | 'D C'        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `pickup_dropoff` column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use a `groupby()` statement to group each row by the new `pickup_dropoff` column, compute the mean, and capture the values only in the `trip_distance` column. Assign the results to a variable named `grouped`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grouped` is an object of the `DataFrame` class.\n",
    "\n",
    "1. Convert it to a dictionary using the [`to_dict()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html) method. Assign the results to a variable called `grouped_dict`. This will result in a dictionary with a key of `trip_distance` whose values are another dictionary. The inner dictionary's keys are pickup/dropoff points and its values are mean distances. This is the information you want.\n",
    "\n",
    "```\n",
    "Example:\n",
    "grouped_dict = {'trip_distance': {'A B': 1.25, 'C D': 2, 'D C': 3}\n",
    "```\n",
    "\n",
    "2. Reassign the `grouped_dict` dictionary so it contains only the inner dictionary. In other words, get rid of `trip_distance` as a key, so:\n",
    "\n",
    "```\n",
    "Example:\n",
    "grouped_dict = {'A B': 1.25, 'C D': 2, 'D C': 3}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert `grouped` to a dictionary\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 2. Reassign to only contain the inner dictionary\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a `mean_distance` column that is a copy of the `pickup_dropoff` helper column.\n",
    "\n",
    "2. Use the [`map()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html#pandas-series-map) method on the `mean_distance` series. Pass `grouped_dict` as its argument. Reassign the result back to the `mean_distance` series.\n",
    "</br></br>\n",
    "When you pass a dictionary to the `Series.map()` method, it will replace the data in the series where that data matches the dictionary's keys. The values that get imputed are the values of the dictionary.\n",
    "\n",
    "```\n",
    "Example:\n",
    "df['mean_distance']\n",
    "```\n",
    "\n",
    "|mean_distance |\n",
    "|  :-:         |\n",
    "| 'A B'        |\n",
    "| 'C D'        |\n",
    "| 'A B'        |\n",
    "| 'D C'        |\n",
    "| 'E F'        |\n",
    "\n",
    "```\n",
    "grouped_dict = {'A B': 1.25, 'C D': 2, 'D C': 3}\n",
    "df['mean_distance`] = df['mean_distance'].map(grouped_dict)\n",
    "df['mean_distance']\n",
    "```\n",
    "\n",
    "|mean_distance |\n",
    "|  :-:         |\n",
    "| 1.25         |\n",
    "| 2            |\n",
    "| 1.25         |\n",
    "| 3            |\n",
    "| NaN          |\n",
    "\n",
    "When used this way, the `map()` `Series` method is very similar to `replace()`, however, note that `map()` will impute `NaN` for any values in the series that do not have a corresponding key in the mapping dictionary, so be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a mean_distance column that is a copy of the pickup_dropoff helper column\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# 2. Map `grouped_dict` to the `mean_distance` column\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Confirm that it worked\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `mean_duration` column\n",
    "\n",
    "Repeat the process used to create the `mean_distance` column to create a `mean_duration` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create a dictionary where keys are unique pickup_dropoffs and values are\n",
    "# mean trip duration for all trips with those pickup_dropoff combos\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Confirm that it worked\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `day` and `month` columns\n",
    "\n",
    "Create two new columns, `day` (name of day) and `month` (name of month) by extracting the relevant information from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'day' col\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Create 'month' col\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create `rush_hour` column\n",
    "\n",
    "Define rush hour as:\n",
    "* Any weekday (not Saturday or Sunday) AND\n",
    "* Either from 06:00&ndash;10:00 or from 16:00&ndash;20:00\n",
    "\n",
    "Create a binary `rush_hour` column that contains a 1 if the ride was during rush hour and a 0 if it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'rush_hour' col\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# If day is Saturday or Sunday, impute 0 in `rush_hour` column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the `rush_hourizer()` function to the new column\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Scatter plot\n",
    "\n",
    "Create a scatterplot to visualize the relationship between `mean_duration` and `fare_amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot to visualize the relationship between variables of interest\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mean_duration` variable correlates with the target variable. But what are the horizontal lines around fare amounts of 52 dollars and 63 dollars? What are the values and how many are there?\n",
    "\n",
    "You know what one of the lines represents. 62 dollars and 50 cents is the maximum that was imputed for outliers, so all former outliers will now have fare amounts of \\$62.50. What is the other line?\n",
    "\n",
    "Check the value of the rides in the second horizontal line in the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first 30 of these trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to display all columns\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you notice about the first 30 trips?\n",
    "\n",
    "==> ENTER YOUR RESPONSE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. Isolate modeling variables\n",
    "\n",
    "Drop features that are redundant, irrelevant, or that will not be available in a deployed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. Pair plot\n",
    "\n",
    "Create a pairplot to visualize pairwise relationships between `fare_amount`, `mean_duration`, and `mean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot to visualize pairwise relationships between variables in the data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables all show linear correlation with each other. Investigate this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7. Identify correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, code a correlation matrix to help determine most correlated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix to help determine most correlated variables\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a correlation heatmap of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which variable(s) are correlated with the target variable of `fare_amount`? \n",
    "\n",
    "Try modeling with both variables even though they are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgPul2DiY6T4"
   },
   "source": [
    "<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Construct**\n",
    "\n",
    "After analysis and deriving variables with close relationships, it is time to begin constructing the model. Consider the questions in your PACE Strategy Document to reflect on the Construct stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_QYzJfVUrIc"
   },
   "source": [
    "### Task 8a. Split data into outcome variable and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzcDgLRET4d7"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your X and y variables. X represents the features and y represents the outcome (target) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target column from the features\n",
    "# X = df2.drop(columns='fare_amount')\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Set y variable\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Display first few rows\n",
    "### YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3ArC_5xa7Oi"
   },
   "source": [
    "### Task 8b. Pre-process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdfTaopCcbTj"
   },
   "source": [
    "Dummy encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Y3T2poF28fP"
   },
   "outputs": [],
   "source": [
    "# Convert VendorID to string\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Get dummies\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and testing sets. The test set should contain 20% of the total samples. Set `random_state=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2BNUvacwaZY"
   },
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "#### YOUR CODE HERE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDYyjWssbnBG"
   },
   "source": [
    "### Standardize the data\n",
    "\n",
    "Use `StandardScaler()`, `fit()`, and `transform()` to standardize the `X_train` variables. Assign the results to a variable called `X_train_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the X variables\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk0rjKeO3JLv"
   },
   "source": [
    "### Fit the model\n",
    "\n",
    "Instantiate your model and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SClNm5hWotj6"
   },
   "outputs": [],
   "source": [
    "# Fit your model to the training data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMj6QkK1cLmS"
   },
   "source": [
    "### Task 8c. Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AromLx7t5hjt"
   },
   "source": [
    "### Train data\n",
    "\n",
    "Evaluate your model performance by calculating the residual sum of squares and the explained variance score (R^2). Calculate the Mean Absolute Error, Mean Squared Error, and the Root Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33rE1x9e3U6t"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model performance on the training data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data\n",
    "\n",
    "Calculate the same metrics on the test data. Remember to scale the `X_test` data using the scaler that was fit to the training data. Do not refit the scaler to the testing data, just transform it. Call the results `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X_test data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5nXSpRCVXq6"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model performance on the testing data\n",
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3MCKUhPJLi5"
   },
   "source": [
    "<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n",
    "\n",
    "## PACE: **Execute**\n",
    "\n",
    "Consider the questions in your PACE Strategy Document to reflect on the Execute stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_l3bkxQdJ3a"
   },
   "source": [
    "### Task 9a. Results\n",
    "\n",
    "Use the code cell below to get `actual`,`predicted`, and `residual` for the testing set, and store them as columns in a `results` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSl5gbXfBPBN"
   },
   "outputs": [],
   "source": [
    "# Create a `results` dataframe\n",
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwRmSDS3eyeH"
   },
   "source": [
    "### Task 9b. Visualize model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3vQ-mB51dfd"
   },
   "source": [
    "Create a scatterplot to visualize `actual` vs. `predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBFU_dicBjwQ"
   },
   "outputs": [],
   "source": [
    "# Create a scatterplot to visualize `predicted` over `actual`\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbO71S_R9IcY"
   },
   "source": [
    "Visualize the distribution of the `residuals` using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a0UYoEr9Nx6"
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of the `residuals`\n",
    "### YOUR CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residual mean\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCnELck-9h5M"
   },
   "source": [
    "Create a scatterplot of `residuals` over `predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Kmr2U8A95fY"
   },
   "outputs": [],
   "source": [
    "# Create a scatterplot of `residuals` over `predicted`\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9c. Coefficients\n",
    "\n",
    "Use the `coef_` attribute to get the model's coefficients. The coefficients are output in the order of the features that were used to train the model. Which feature had the greatest effect on trip fare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the model's coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these coefficients mean? How should they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6AlDDyhdzmG"
   },
   "source": [
    "### Task 9d. Conclusion\n",
    "\n",
    "1. What are the key takeaways from this notebook?\n",
    "\n",
    "\n",
    "\n",
    "2. What results can be presented from this notebook?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> ENTER YOUR RESPONSE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
